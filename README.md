The increasing demand for integrating low-power
devices into an established wireless infrastructure necessitates
the development of inventive wireless connectivity strategies
that are both energy-efficient and spectrum-efficient. To this
end, this paper investigates the uplink communication of an
energy harvesting (EH)-enabled resource-constrained secondary
device (RCSD) coexisting with primary devices in a cognitive
radio-aided non-orthogonal multi-access (CR-NOMA) network.
Assuming a non-linear EH model in practice, the data rate
of the RCSD is maximized using deep reinforcement learning
(DRL). We first derive the optimal solutions for the parameters of
interest including the time-sharing coefficient and transmit power
of the RCSD, using convex optimization and then implement
the DRL to address a continuous action spaced optimization
problem. To comprehensively assess the agent’s performance and
adaptability, we implement various DRL algorithms and compare
them under non-linear EH, which reveals their suitability in
various scenarios, aiding in selecting the most effective approach.
Index Terms—Energy harvesting, deep reinforcement learning,
convex optimization, and deep deterministic policy gradient.
